{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCS Demonstration and Development Benchmark\n",
    "\n",
    "(cc) conrad.jackisch@tbt.tu-freiberg.de, antita.sanchez@mineral.tu-freiberg.de  \n",
    "\n",
    "This notebook demonstrates the integrated hysteresis analysis package GCS combining four methods:\n",
    "1. **HARP** (Roberts et al., 2023) - Empirical classification based on peak timing and loop geometry\n",
    "2. **Zuecco** (Zuecco et al., 2016) - Integration-based index with 9-class classification\n",
    "3. **Lloyd/Lawler** (Lloyd et al., 2016; Lawler et al., 2006) - Percentile-based indices\n",
    "4. **Musolff/Thompson** (Musolff et al., 2015; Thompson et al., 2011) - ratio of CV of C and Q \n",
    "\n",
    "It is intended as a functionality benchmark using the same reference as the Zuecco package https://github.com/florianjehn/Hysteresis-Index-Zuecco and HARP package https://github.com/MelanieEmmajade/HARP.\n",
    "It shall enable a critical usage of the C-Q analysis in the sense of Knapp and Musolff, 2024 https://doi.org/10.1002/hyp.15328.\n",
    "\n",
    "## HOW THE THREE METHODS COMPLEMENT EACH OTHER\n",
    "\n",
    "### HARP METHOD\n",
    " - Provides qualitative empirical classifica\n",
    " - Identifies process timing (flushing vs. dilution)\n",
    " - Easy interpretation with named classes\n",
    " - Best for: First-pass analysis and process identification\n",
    "\n",
    "### ZUECCO METHOD\n",
    " - Quantifies loop area and hysteresis strength\n",
    " - 9-class system captures subtle variations\n",
    " - Detects mixed clockwise/counter-clockwise patterns\n",
    " - Best for: Quantitative comparisons and complex patterns\n",
    "\n",
    "### LLOYD/LAWLER METHODS\n",
    " - Percentile-based for standard comparisons\n",
    " - HInew has symmetric range [-1, 1]\n",
    " - Shows flow-dependent hysteresis\n",
    " - Best for: Publication-quality quantification\n",
    "\n",
    "### MUSLOFF/THOMPSON METHODS\n",
    " - Analysis in ∆C/∆Q and statistical spaces of their covariates\n",
    "\n",
    "**✓ CONVERGENT EVIDENCE = HIGH CONFIDENCE**\n",
    "When all three methods agree → Strong, unambiguous pattern\n",
    "\n",
    "**⚠️ DIVERGENT RESULTS = INVESTIGATE FURTHER**\n",
    "When methods disagree → Complex/mixed pattern\n",
    "\n",
    "## GEOCHEMICAL CLASSIFICATION AND RESULT VISUALIZATION\n",
    "\n",
    "Above the standard classifications from the individual methods and an evaluation about their coherence, the package contains a percentile and C/Q analysis based classification approach, which is developed for Sanchez et al. 2025 (in review). \n",
    "\n",
    "To evaluate its basis and to deeply dive into the actual structure of the C-Q dynamics, we provide several comprehensive plotting options. \n",
    "\n",
    "## DISCLAIMER\n",
    "\n",
    "Despite all testing and care, this code is scientific and experimental. Do not trust the results before throughout analysis. The code has a couple of more or less hard-coded assumptions (like usual time series in days and spline interpolations) which might completely skew up under untested circumstances. Feel free to fork, contribute, extend with cc-by."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import sys\n",
    "sys.path.append('../hygcs')\n",
    "# Import the integrated hysteresis system (v4 - for event-scale analysis)\n",
    "import gcs as gcs\n",
    "\n",
    "# Import individual methods and plotting functions\n",
    "from harp import calculate_harp_metrics, harp_plot\n",
    "from zuecco import calculate_zuecco_metrics, zuecco_plot\n",
    "from lloyd import calculate_lawlerlloyd_metrics, lloyd_plot\n",
    "\n",
    "# Note: For time series classification, we'll use gcs_v5 (imported in Section 6)\n",
    "\n",
    "print(\"✓ All modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example datasets\n",
    "sheet_names = [\"soil_1\", \"soil_2\", \"connectivity_1\", \"connectivity_2\"]\n",
    "\n",
    "datasets = {}\n",
    "for idx, name in enumerate(sheet_names):\n",
    "    df = pd.read_excel(\n",
    "        \"hysteresis_examples.xlsx\",\n",
    "        sheet_name=idx,\n",
    "        index_col=0\n",
    "    ).reset_index()\n",
    "    datasets[name] = df\n",
    "    print(f\"Loaded {name}: {len(df)} points, columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single Event Analysis - Complete Workflow\n",
    "\n",
    "We'll analyze the `soil_2` dataset in detail, demonstrating all three methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataset for detailed analysis\n",
    "test_data = datasets['soil_2'].copy()\n",
    "\n",
    "# Extract column names\n",
    "time_col = test_data.columns[0]\n",
    "discharge_col = test_data.columns[1]\n",
    "concentration_col = test_data.columns[2]\n",
    "\n",
    "print(f\"Analyzing: soil_2 dataset\")\n",
    "print(f\"  Time: {time_col}\")\n",
    "print(f\"  Discharge: {discharge_col}\")\n",
    "print(f\"  Concentration: {concentration_col}\")\n",
    "print(f\"  Data points: {len(test_data)}\")\n",
    "print(f\"  Time range: {test_data[time_col].min()} to {test_data[time_col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Calculate All Hysteresis Metrics\n",
    "\n",
    "The `calculate_all_hysteresis_metrics()` function is our comprehensive wrapper that applies all three methods to the event data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all metrics\n",
    "all_metrics = gcs.calculate_all_hysteresis_metrics(\n",
    "    test_data,\n",
    "    time_col=time_col,\n",
    "    discharge_col=discharge_col,\n",
    "    concentration_col=concentration_col\n",
    ")\n",
    "\n",
    "# Check for errors\n",
    "if 'error' in all_metrics and all_metrics['error'] != 'None':\n",
    "    print(f\"⚠️ Error occurred: {all_metrics['error']}\")\n",
    "else:\n",
    "    print(\"✓ All metrics calculated successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculate the individual metrics for direct testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_metrics, harp_df = gcs.calculate_harp_metrics(test_data, time_col=time_col, discharge_col=discharge_col, concentration_col=concentration_col)\n",
    "harp_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zuecco_metrics, zuecco_df = gcs.calculate_zuecco_metrics(test_data, time_col=time_col, discharge_col=discharge_col, concentration_col=concentration_col)\n",
    "zuecco_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lloyd_metrics, lloyd_df = gcs.calculate_lawlerlloyd_metrics(test_data, time_col=time_col, discharge_col=discharge_col, concentration_col=concentration_col)\n",
    "lloyd_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 HARP Method Results\n",
    "\n",
    "**HARP (Hysteresis Analysis of Rising and Falling Peaks)** uses empirical classification based on:\n",
    "- Peak timing difference between Q and C\n",
    "- Loop shape and area\n",
    "- Residual (end-state deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_metrics = all_metrics['harp_metrics']\n",
    "\n",
    "print(\"═\" * 60)\n",
    "print(\"HARP METHOD RESULTS\")\n",
    "print(\"═\" * 60)\n",
    "\n",
    "if harp_metrics:\n",
    "    print(f\"\\nKey Metrics:\")\n",
    "    print(f\"  • Loop Area: {harp_metrics.get('area', np.nan):.4f}\")\n",
    "    print(f\"  • Residual: {harp_metrics.get('residual', np.nan):.4f}\")\n",
    "    print(f\"  • Peak Q timing: {harp_metrics.get('peaktime_Q', np.nan):.4f} days\")\n",
    "    print(f\"  • Peak C timing: {harp_metrics.get('peaktime_C', np.nan):.4f} days\")\n",
    "    \n",
    "    # Interpret peak timing\n",
    "    peak_q = harp_metrics.get('peaktime_Q', np.nan)\n",
    "    peak_c = harp_metrics.get('peaktime_C', np.nan)\n",
    "    if not np.isnan(peak_q) and not np.isnan(peak_c):\n",
    "        diff = peak_c - peak_q\n",
    "        if diff < 0:\n",
    "            timing_interp = f\"C peaks {abs(diff):.2f} days BEFORE Q → Flushing/mobilization\"\n",
    "        elif diff > 0:\n",
    "            timing_interp = f\"C peaks {diff:.2f} days AFTER Q → Dilution/depletion\"\n",
    "        else:\n",
    "            timing_interp = \"Peaks coincide → Complex/mixed\"\n",
    "        print(f\"\\nInterpretation: {timing_interp}\")\n",
    "else:\n",
    "    print(\"No HARP metrics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Zuecco Method Results\n",
    "\n",
    "**Zuecco Index** calculates the integrated area between rising and falling limbs:\n",
    "- h_index: Sum of differential areas (can be positive or negative)\n",
    "- 9-class classification system (0-8)\n",
    "- Classes 1-4: Clockwise variants\n",
    "- Classes 5-8: Counter-clockwise variants\n",
    "- Class 0: Linear/no hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zuecco_metrics = all_metrics['zuecco_metrics']\n",
    "\n",
    "print(\"═\" * 60)\n",
    "print(\"ZUECCO METHOD RESULTS\")\n",
    "print(\"═\" * 60)\n",
    "\n",
    "if zuecco_metrics:\n",
    "    h_index = zuecco_metrics.get('h_index', np.nan)\n",
    "    hyst_class = zuecco_metrics.get('hyst_class', -1)\n",
    "    \n",
    "    print(f\"\\nClassification: Class {hyst_class}\")\n",
    "    print(f\"\\nKey Metrics:\")\n",
    "    print(f\"  • h-index: {h_index:.4f}\")\n",
    "    print(f\"  • Min differential area: {zuecco_metrics.get('min_diff_area', np.nan):.6f}\")\n",
    "    print(f\"  • Max differential area: {zuecco_metrics.get('max_diff_area', np.nan):.6f}\")\n",
    "    \n",
    "    # Interpret h-index magnitude\n",
    "    if not np.isnan(h_index):\n",
    "        if h_index > 0.1:\n",
    "            mag_interp = \"Strong clockwise hysteresis\"\n",
    "        elif h_index > 0.01:\n",
    "            mag_interp = \"Moderate clockwise hysteresis\"\n",
    "        elif h_index > -0.01:\n",
    "            mag_interp = \"Weak/no hysteresis\"\n",
    "        elif h_index > -0.1:\n",
    "            mag_interp = \"Moderate counter-clockwise hysteresis\"\n",
    "        else:\n",
    "            mag_interp = \"Strong counter-clockwise hysteresis\"\n",
    "        print(f\"\\nInterpretation: {mag_interp}\")\n",
    "else:\n",
    "    print(\"No Zuecco metrics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Lloyd/Lawler Method Results\n",
    "\n",
    "**Two complementary percentile-based methods:**\n",
    "\n",
    "1. **Lloyd et al. (2016) - HInew (RECOMMENDED)**\n",
    "   - Difference-based: `HI = (C_rise - C_fall) / C_mid`\n",
    "   - Symmetric range: [-1, 1]\n",
    "   - Better comparability\n",
    "\n",
    "2. **Lawler et al. (2006) - HIL (ORIGINAL)**\n",
    "   - Ratio-based: `HI = (C_rise / C_fall) - 1` or `(-1 / ratio) + 1`\n",
    "   - Asymmetric range\n",
    "   - More sensitive at extremes\n",
    "\n",
    "Both sample at 9 discharge percentiles (0.1 to 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lloyd_metrics = all_metrics['lloyd_metrics']\n",
    "classifications = all_metrics['classifications']\n",
    "\n",
    "print(\"═\" * 60)\n",
    "print(\"LLOYD/LAWLER METHOD RESULTS\")\n",
    "print(\"═\" * 60)\n",
    "\n",
    "if lloyd_metrics:\n",
    "    # Lloyd (2016) - Recommended method\n",
    "    print(\"\\nLLOYD (2016) - DIFFERENCE METHOD [RECOMMENDED]\")\n",
    "    print(f\"   Direction: {classifications.get('lloyd_direction', 'unknown')}\")\n",
    "    print(f\"\\n   Key Metrics:\")\n",
    "    print(f\"     • Mean HInew: {lloyd_metrics.get('mean_HInew', np.nan):.4f}\")\n",
    "    print(f\"     • Median HInew: {lloyd_metrics.get('median_HInew', np.nan):.4f}\")\n",
    "    print(f\"     • HInew Range: {lloyd_metrics.get('HInew_range', np.nan):.4f}\")\n",
    "    \n",
    "    # Lawler (2006) - Original method\n",
    "    print(\"\\nLAWLER (2006) - RATIO METHOD [COMPARISON]\")\n",
    "    print(f\"   Direction: {classifications.get('lawler_direction', 'unknown')}\")\n",
    "    print(f\"\\n   Key Metrics:\")\n",
    "    print(f\"     • Mean HIL: {lloyd_metrics.get('mean_HIL', np.nan):.4f}\")\n",
    "    print(f\"     • Median HIL: {lloyd_metrics.get('median_HIL', np.nan):.4f}\")\n",
    "    \n",
    "    # Magnitude interpretation\n",
    "    mean_hinew = lloyd_metrics.get('mean_HInew', np.nan)\n",
    "    if not np.isnan(mean_hinew):\n",
    "        if abs(mean_hinew) > 0.5:\n",
    "            strength = \"STRONG\"\n",
    "        elif abs(mean_hinew) > 0.2:\n",
    "            strength = \"MODERATE\"\n",
    "        elif abs(mean_hinew) > 0.05:\n",
    "            strength = \"WEAK\"\n",
    "        else:\n",
    "            strength = \"NEGLIGIBLE\"\n",
    "        print(f\"\\nInterpretation: {strength} hysteresis (|HInew| = {abs(mean_hinew):.3f})\")\n",
    "else:\n",
    "    print(\"No Lloyd/Lawler metrics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visual Analysis - All Three Methods\n",
    "\n",
    "Now let's visualize the results from each method. We'll call the individual calculation functions to get the complete DataFrames with attrs needed for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics using individual functions to get full DataFrames with attrs\n",
    "harp_metrics_df, harp_df = gcs.calculate_harp_metrics(\n",
    "    test_data, time_col=time_col, \n",
    "    discharge_col=discharge_col, \n",
    "    concentration_col=concentration_col\n",
    ")\n",
    "\n",
    "zuecco_metrics_df, zuecco_df = gcs.calculate_zuecco_metrics(\n",
    "    test_data, time_col=time_col, \n",
    "    discharge_col=discharge_col, \n",
    "    concentration_col=concentration_col\n",
    ")\n",
    "\n",
    "lloyd_metrics_df, lloyd_df = gcs.calculate_lawlerlloyd_metrics(\n",
    "    test_data, time_col=time_col, \n",
    "    discharge_col=discharge_col, \n",
    "    concentration_col=concentration_col\n",
    ")\n",
    "\n",
    "print(\"✓ Individual metrics calculated for plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_harp = gcs.harp_plot(harp_df, harp_metrics_df)\n",
    "fig_harp.update_layout(title=\"HARP Analysis - soil_2 Dataset\")\n",
    "fig_harp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Zuecco Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_zuecco = gcs.zuecco_plot(zuecco_df, zuecco_metrics_df)\n",
    "fig_zuecco.update_layout(title=\"Zuecco Analysis - soil_2 Dataset\")\n",
    "fig_zuecco.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Lloyd/Lawler Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lloyd = gcs.lloyd_plot(lloyd_df, lloyd_metrics_df)\n",
    "fig_lloyd.update_layout(title=\"Lloyd/Lawler Analysis - soil_2 Dataset\")\n",
    "fig_lloyd.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparative Analysis - All Four Datasets\n",
    "\n",
    "Let's analyze all four example datasets to compare hysteresis patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all datasets\n",
    "results_summary = []\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    time_col = df.columns[0]\n",
    "    discharge_col = df.columns[1]\n",
    "    concentration_col = df.columns[2]\n",
    "    \n",
    "    metrics = gcs.calculate_all_hysteresis_metrics(\n",
    "        df, time_col=time_col, \n",
    "        discharge_col=discharge_col, \n",
    "        concentration_col=concentration_col\n",
    "    )\n",
    "    \n",
    "    # Extract key metrics\n",
    "    harp_m = metrics['harp_metrics']\n",
    "    zuecco_m = metrics['zuecco_metrics']\n",
    "    lloyd_m = metrics['lloyd_metrics']\n",
    "    class_m = metrics['classifications']\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Dataset': name,\n",
    "        'N_points': len(df),\n",
    "        'HARP_area': harp_m.get('area', np.nan),\n",
    "        'Zuecco_h_index': zuecco_m.get('h_index', np.nan),\n",
    "        'Zuecco_class': zuecco_m.get('hyst_class', -1),\n",
    "        'Lloyd_mean_HInew': lloyd_m.get('mean_HInew', np.nan),\n",
    "        'Lloyd_direction': class_m.get('lloyd_direction', 'unknown'),\n",
    "        'Lawler_mean_HIL': lloyd_m.get('mean_HIL', np.nan)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "print(\"\\n\" + \"═\" * 100)\n",
    "print(\"COMPARATIVE SUMMARY - ALL DATASETS\")\n",
    "print(\"═\" * 100)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual comparison\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\n",
    "        f\"{name}<br>Lloyd HI={summary_df.loc[i, 'Lloyd_mean_HInew']:.3f}, Zuecco={summary_df.loc[i, 'Zuecco_class']}\"\n",
    "        for i, name in enumerate(sheet_names)\n",
    "    ],\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "           [{'type': 'scatter'}, {'type': 'scatter'}]]\n",
    ")\n",
    "\n",
    "for idx, (name, df) in enumerate(datasets.items()):\n",
    "    row = idx // 2 + 1\n",
    "    col = idx % 2 + 1\n",
    "    \n",
    "    # Normalize data for plotting\n",
    "    Q = df.iloc[:, 1].values\n",
    "    C = df.iloc[:, 2].values\n",
    "    Q_norm = (Q - Q.min()) / (Q.max() - Q.min()) if Q.max() > Q.min() else Q\n",
    "    C_norm = (C - C.min()) / (C.max() - C.min()) if C.max() > C.min() else C\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=Q_norm, y=C_norm,\n",
    "            mode='lines+markers',\n",
    "            marker=dict(size=4, color=np.arange(len(Q_norm)), colorscale='Viridis'),\n",
    "            line=dict(color='gray', width=1),\n",
    "            name=name,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Q (normalized)\", row=row, col=col)\n",
    "    fig.update_yaxes(title_text=\"C (normalized)\", row=row, col=col)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Hysteresis Loops - All Datasets (colored by time)\",\n",
    "    height=700,\n",
    "    template='none'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Overall Conclusions\n",
    "\n",
    "**For Event-Scale Hysteresis Analysis:**\n",
    "- **Use all three methods** for robust analysis\n",
    "- **Lloyd HInew** recommended for standard reporting\n",
    "- **Zuecco** excellent for complex/mixed patterns\n",
    "- **HARP** intuitive for process identification\n",
    "- **Convergent evidence** = high confidence\n",
    "\n",
    "**For Time Series Classification (GCS v5.0):**\n",
    "- **Integrates hysteresis + C-Q dynamics** for mechanistic phase classification\n",
    "- **C-Q slopes** reveal connectivity patterns (dilution vs enrichment)\n",
    "- **Window-scale hysteresis** captures temporal dynamics correctly\n",
    "- **Percentile-based** thresholds work across compounds\n",
    "- **6 phases** (F, L, C, D, R, V) capture geochemical behavior\n",
    "\n",
    "### Differences Between Approaches:\n",
    "\n",
    "| Aspect | Event Hysteresis | GCS Time Series |\n",
    "|--------|------------------|-----------------|\n",
    "| **Scope** | Single event (storm, flush) | Multiple cycles over time |\n",
    "| **Input** | One C-Q loop | Time series with many points |\n",
    "| **Output** | HI, class, metrics | Phase per segment + confidence |\n",
    "| **Hysteresis** | Event-scale | Window-scale per segment |\n",
    "| **Best for** | Understanding single events | Long-term monitoring analysis |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Hydro-Geochemical Classification Suite (HyGCS)** integrates hysteresis analysis with C-Q dynamics to classify time series data into geochemical phases:\n",
    "\n",
    "- **F (Flushing)**: Dilution-dominated, steep C decline during high Q\n",
    "- **L (Loading)**: Enrichment before peak, C increase with Q\n",
    "- **C (Chemostatic)**: Buffered, low CVc/CVq, flat C-Q slope\n",
    "- **D (Dilution)**: Post-flush recovery, depleted sources\n",
    "- **R (Recession)**: Late cycle, low variability, connectivity loss\n",
    "- **V (Variable)**: Mixed/ambiguous patterns\n",
    "\n",
    "**Note:** HyGCS expects **time series data** with multiple sampling points, whereas the HARP/Lloyd/Zuecco examples are single-event hysteresis loops. We'll demonstrate the classifier conceptually using a shortened time series. Please head to `test_gcs.ipynb` to continue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelling_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
